# -*- coding: utf-8 -*-
"""finalcopy of editHD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZL0qexwfuSVOrvJYw6QfaXJT6UJJlqBt
"""

# from google.colab import drive
# drive.mount("/content/drive")

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report
# df2 = pd.read_csv("/content/drive/My Drive/heart.csv", na_values=np.nan)
df2 = pd.read_csv("heart.csv", na_values=np.nan)
df2.head()

from sklearn import preprocessing
enc = preprocessing.OrdinalEncoder()
enc.fit(df2)
enc.transform(df2)

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
imp = IterativeImputer(max_iter=10, random_state=0)
imp.fit(df2)
df2.head()

#target

y = df2["target"]
sns.countplot(y)
target_temp = df2.target.value_counts()

print(target_temp)

print("Percentage of patients  without heart problems: "+str(round(target_temp[0]*100/303,2)))
print("Percentage of patients with heart problems: "+str(round(target_temp[1]*100/303,2)))

#analysing sex feature
df2["sex"].unique()

sns.barplot(df2["sex"],y)

"""females are more likely to have heart problems than males

"""

#analysing chesttype feature
df2["cp"].unique()

sns.barplot(df2["cp"],y)

pd.crosstab(df2.age,df2.target).plot(kind="bar",figsize=(20,6))
plt.title('Heart Disease Frequency for Ages')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.savefig('heartDiseaseAndAges.png')
plt.show()

#analysing fbs feature
df2["fbs"].describe()

df2["fbs"].unique()

sns.barplot(df2["fbs"],y)

#Analysing the restecg feature
df2["restecg"].unique()

sns.barplot(df2["restecg"],y)

#Analysing extang feature
df2["exang"].unique()

sns.barplot(df2["exang"],y)

#Analysing ca feature
df2["ca"].unique()

sns.countplot(df2["ca"])

#Analysing 'thal' feature
df2["thal"].unique()

sns.barplot(df2["thal"],y)

sns.distplot(df2["thal"])

"""Train test split

"""

df2.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',
       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']

cnames=['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression','num_major_vessels']

corr_matrix = df2.corr()
top_corr_feature = corr_matrix.index
plt.figure(figsize=(8, 8))
sns.heatmap(df2[top_corr_feature].corr(), annot=True, cmap="RdYlGn", annot_kws={"size":8})

#train test split
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

predictors = df2.drop("target",axis=1)
target = df2["target"]

X_train,X_test,Y_train,Y_test = train_test_split(predictors,target,test_size=0.20,random_state=0)

X_train.shape

X_test.shape

Y_train.shape

Y_test.shape

from sklearn.metrics import accuracy_score

"""Training classifiers."""

#logistic regression
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()

lr.fit(X_train,Y_train)

Y_pred_lr = lr.predict(X_test)

score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)

print("The accuracy score achieved using Logistic Regression is: "+str(score_lr)+" %")

matrix= confusion_matrix(Y_test, Y_pred_lr)
sns.heatmap(matrix,annot = True, fmt = "d")

print(classification_report(Y_test,Y_pred_lr))

#Naive Bayes
from sklearn.naive_bayes import GaussianNB

nb = GaussianNB()

nb.fit(X_train,Y_train)

Y_pred_nb = nb.predict(X_test)

score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)

print("The accuracy score achieved using Naive Bayes is: "+str(score_nb)+" %")

matrix= confusion_matrix(Y_test, Y_pred_nb)
sns.heatmap(matrix,annot = True, fmt = "d")

print(classification_report(Y_test,Y_pred_nb))

#SVM
from sklearn import svm

sv = svm.SVC(kernel='linear')

sv.fit(X_train, Y_train)

Y_pred_svm = sv.predict(X_test)

score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)

print("The accuracy score achieved using Linear SVM is: "+str(score_svm)+" %")

print(classification_report(Y_test,Y_pred_svm))

matrix= confusion_matrix(Y_test, Y_pred_svm)
sns.heatmap(matrix,annot = True, fmt = "d")

#KNN
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(X_train,Y_train)
Y_pred_knn=knn.predict(X_test)

score_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)

print("The accuracy score achieved using KNN is: "+str(score_knn)+" %")

print(classification_report(Y_test,Y_pred_knn))

matrix= confusion_matrix(Y_test, Y_pred_knn)
sns.heatmap(matrix,annot = True, fmt = "d")

#Extra Tree
from sklearn.ensemble import ExtraTreesClassifier
et = ExtraTreesClassifier()

et.fit(X_train,Y_train)

Y_pred_et = et.predict(X_test)

score_et= round(accuracy_score(Y_pred_et,Y_test)*100,2)

print("The accuracy score achieved using Extra Tree is: "+str(score_et)+" %")

print(classification_report(Y_test,Y_pred_et))

matrix= confusion_matrix(Y_test, Y_pred_et)
sns.heatmap(matrix,annot = True, fmt = "d")

#DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier

max_accuracy = 0


for x in range(200):
    dt = DecisionTreeClassifier(random_state=x)
    dt.fit(X_train,Y_train)
    Y_pred_dt = dt.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x

dt = DecisionTreeClassifier(random_state=best_x)
dt.fit(X_train,Y_train)
Y_pred_dt = dt.predict(X_test)

score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)

print("The accuracy score achieved using Decision Tree is: "+str(score_dt)+" %")

matrix=confusion_matrix(Y_test,Y_pred_dt)
sns.heatmap(matrix,annot= True,fmt="d")

print(classification_report(Y_test,Y_pred_dt))

#RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier

max_accuracy = 0


for x in range(200):
    rf = RandomForestClassifier(random_state=x)
    rf.fit(X_train,Y_train)
    Y_pred_rf = rf.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_rf,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x
        

rf = RandomForestClassifier(random_state=best_x)
rf.fit(X_train,Y_train)
Y_pred_rf = rf.predict(X_test)

score_rf = round(accuracy_score(Y_pred_rf,Y_test)*100,2)

print("The accuracy score achieved using Random Forest is: "+str(score_rf)+" %")

matrix=confusion_matrix(Y_test,Y_pred_rf)
sns.heatmap(matrix,annot=True,fmt="d")

print(classification_report(Y_test,Y_pred_rf))

#Neural Network
from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(11,activation='relu',input_dim=13))
model.add(Dense(1,activation='sigmoid'))

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

model.fit(X_train,Y_train,epochs=300)

Y_pred_nn = model.predict(X_test)

rounded = [round(x[0]) for x in Y_pred_nn]

Y_pred_nn = rounded

score_nn = round(accuracy_score(Y_pred_nn,Y_test)*100,2)

print("The accuracy score achieved using Neural Network is: "+str(score_nn)+" %")

matrix=confusion_matrix(Y_test,Y_pred_nn)
sns.heatmap(matrix,annot=True,fmt="d")

print(classification_report(Y_test,Y_pred_nn))

from sklearn.ensemble import VotingClassifier
majority_voting = VotingClassifier(estimators, voting='hard')

vote = VotingClassifier(estimators = [('svc',sv),('dt',dt),('rf',rf),('nb', nb),('et',et),('knn',knn)])
vote.fit(X_train,Y_train) 
Y_pred_vote = vote.predict(X_test)
vote_score=vote.score(X_test,Y_test)*100
print("Voting C. Test Score: ",vote.score(X_test,Y_test))
print("Voting C. Train Score: ",vote.score(X_train,Y_train))

print(classification_report(Y_test,Y_pred_vote))

y_preds = vote.predict(X_test)
import pylab as plt
labels=[0,1]
matrix=confusion_matrix(Y_test,y_preds)
sns.heatmap(matrix,annot=True,fmt="d")
fig = plt.figure()

from sklearn.metrics import roc_curve
fpr, tpr, thresholds = roc_curve(Y_test, y_preds)
plt.plot(fpr,tpr)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.title('ROC curve for Heart disease classifier')
plt.xlabel('False positive rate (1-Specificity)')
plt.ylabel('True positive rate (Sensitivity)')
plt.grid(True)

scores = [score_lr,score_nb,score_svm,score_knn,score_et,score_dt,score_rf,vote_score]
algorithms = ["Logistic Regression","Naive Bayes","SVM","K-Nearest Neighbors","Extra Tree","Decision Tree","Random Forest","Voting"] 
sns.set(rc={'figure.figsize':(15,8)})
plt.xlabel("Algorithms")
plt.ylabel("Accuracy score")
sns.barplot(algorithms,scores)